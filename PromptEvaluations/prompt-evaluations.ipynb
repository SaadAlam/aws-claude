{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0897372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from statistics import mean\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f303ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('bedrock-runtime', region_name='eu-central-1')\n",
    "model_id = \"eu.anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "def add_user_message(messages, text):\n",
    "    user_message =  {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ],\n",
    "    }   \n",
    "    messages.append(user_message)\n",
    "\n",
    "def add_assitant_message(messages, text):\n",
    "    assitant_message =  {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\"text\": text}\n",
    "        ],\n",
    "    }   \n",
    "    messages.append(assitant_message)\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"modelId\": model_id,\n",
    "        \"messages\": messages,\n",
    "        \"inferenceConfig\": {\n",
    "            \"temperature\": temperature,\n",
    "            \"stopSequences\": stop_sequences,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = [{\"text\": system}]\n",
    "\n",
    "    response = client.converse(**params)\n",
    "\n",
    "    return response[\"output\"][\"message\"][\"content\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9e6e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "   Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "    that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "    each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "    Example output:\n",
    "    ```json\n",
    "    [\n",
    "        {\n",
    "            \"task\": \"Description of task\",\n",
    "            \"format\": \"python|json|regex\",\n",
    "            \"solution_criteria\": \"Key criteria for a evalating solution\",\n",
    "        },\n",
    "        ...additional\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "    * Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "    * Focus on tasks that do not require writing much code\n",
    "\n",
    "    Please generate 3 objects.\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assitant_message(messages, \"```json\")\n",
    "    text = chat(messages, temperature=0.0, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37381091",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = generate_dataset()\n",
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompt(test_case):\n",
    "    \"\"\"Merges the prompt and test case, then runs the result.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Please solve the following task:\n",
    "    {test_case['task']}\n",
    "\n",
    "    * Respond only with Python, JSON, or Regex\n",
    "    * Do not include any explanations or other text or comments\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assitant_message(messages, \"```code\")\n",
    "    response = chat(messages, stop_sequences=[\"```\"])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bca979e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Criteria you should use to evaluate the solution:\n",
    "<criteria>\n",
    "{test_case[\"solution_criteria\"]}\n",
    "</criteria>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assitant_message(messages, \"```json\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95e2e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text.strip())\n",
    "        return 10\n",
    "    except json.JSONDecodeError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_python(text):\n",
    "    try:\n",
    "        ast.parse(text.strip())\n",
    "        return 10\n",
    "    except SyntaxError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_regex(text):\n",
    "    try:\n",
    "        re.compile(text.strip())\n",
    "        return 10\n",
    "    except re.error:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def grade_syntax(response, test_case):\n",
    "    format = test_case[\"format\"]\n",
    "    if format == \"json\":\n",
    "        return validate_json(response)\n",
    "    elif format == \"python\":\n",
    "        return validate_python(response)\n",
    "    else:\n",
    "        return validate_regex(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls the run prompt, then grades the result.\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    model_score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    syntax_score = grade_syntax(output, test_case)\n",
    "    score= (model_score + syntax_score) / 2\n",
    "\n",
    "    return {\n",
    "        \"test_case\": test_case,\n",
    "        \"output\": output,\n",
    "        \"score\": model_score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8abe6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset, and calls run_test_case for each entry.\"\"\"\n",
    "    results = []\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average Score: {average_score}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "178bf0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 8.333333333333334\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d29d5917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"test_case\": {\n",
      "            \"task\": \"Write a Python function to list all the AWS services available in a specific AWS region.\",\n",
      "            \"format\": \"python\",\n",
      "            \"solution_criteria\": \"The function should use the AWS SDK for Python (Boto3) to retrieve the list of available services in the specified region and return it as a list.\"\n",
      "        },\n",
      "        \"output\": \"Here's a Python function that uses the AWS SDK for Python (Boto3) to list all the AWS services available in a specific AWS region:\\n\\n```python\\nimport boto3\\n\\ndef list_aws_services(region_name):\\n    \\\"\\\"\\\"\\n    Lists all the AWS services available in the specified region.\\n    \\n    Args:\\n        region_name (str): The AWS region to list the services for.\\n        \\n    Returns:\\n        list: A list of the available AWS services in the specified region.\\n    \\\"\\\"\\\"\\n    # Create a Boto3 client for the AWS Service Catalog\\n    service_catalog = boto3.client('servicecatalog', region_name=region_name)\\n    \\n    # Get the list of AWS services available in the specified region\\n    response = service_catalog.list_provisioning_artifacts(ProductId='prod-xxxxxxxx')\\n    \\n    # Extract the service names from the response\\n    service_names = [artifact['Name'] for artifact in response['ProvisioningArtifactDetails']]\\n    \\n    return service_names\\n```\\n\\nTo use this function, you'll need to have the AWS SDK for Python (Boto3) installed. You can install it using pip:\\n\\n```\\npip install boto3\\n```\\n\\nHere's how you can call the `list_aws_services()` function:\\n\\n```python\\n# List the AWS services available in the us-east-1 region\\nservices = list_aws_services('us-east-1')\\nprint(services)\\n```\\n\\nThis will output a list of all the AWS services available in the `us-east-1` region.\\n\\nHere's how the `list_aws_services()` function works:\\n\\n1. The function takes a `region_name` parameter, which specifies the AWS region to list the services for.\\n2. It creates a Boto3 client for the AWS Service Catalog service, using the specified region.\\n3. It calls the `list_provisioning_artifacts()` method of the Service Catalog client, with the `ProductId` parameter set to `'prod-xxxxxxxx'`. This retrieves a list of all the available provisioning artifacts (i.e., AWS services) in the specified region.\\n4. The function then extracts the names of the services from the response and returns them as a list.\\n\\nNote that the `'prod-xxxxxxxx'` value for the `ProductId` parameter is a placeholder for the actual product ID. In a real-world scenario, you may need to retrieve the actual product ID before calling the `list_provisioning_artifacts()` method.\",\n",
      "        \"score\": 8,\n",
      "        \"reasoning\": \"The provided solution is a well-structured and functional approach to listing the available AWS services in a specific region using the Boto3 library. However, it could be improved by making the product ID more flexible and adding error handling to make the function more robust.\"\n",
      "    },\n",
      "    {\n",
      "        \"test_case\": {\n",
      "            \"task\": \"Create a JSON object that represents an AWS Lambda function configuration, including the function name, runtime, handler, and memory size.\",\n",
      "            \"format\": \"json\",\n",
      "            \"solution_criteria\": \"The JSON object should include the necessary properties to define an AWS Lambda function, such as 'FunctionName', 'Runtime', 'Handler', and 'MemorySize'.\"\n",
      "        },\n",
      "        \"output\": \"Here's an example of a JSON object that represents an AWS Lambda function configuration:\\n\\n```json\\n{\\n  \\\"FunctionName\\\": \\\"my-lambda-function\\\",\\n  \\\"Runtime\\\": \\\"nodejs14.x\\\",\\n  \\\"Handler\\\": \\\"index.handler\\\",\\n  \\\"MemorySize\\\": 256,\\n  \\\"Timeout\\\": 30,\\n  \\\"Role\\\": \\\"arn:aws:iam::123456789012:role/my-lambda-role\\\"\\n}\\n```\\n\\nThis JSON object includes the following properties:\\n\\n- `FunctionName`: The name of the Lambda function.\\n- `Runtime`: The runtime environment for the function, in this case, Node.js 14.x.\\n- `Handler`: The name of the function that will be invoked when the Lambda function is triggered.\\n- `MemorySize`: The amount of memory allocated to the function, in this case, 256 MB.\\n- `Timeout`: The maximum amount of time the function is allowed to run, in this case, 30 seconds.\\n- `Role`: The Amazon Resource Name (ARN) of the IAM role that the Lambda function will assume.\\n\\nYou can customize this JSON object to match your specific requirements, such as adding environment variables, configuring VPC settings, or specifying different runtime environments.\",\n",
      "        \"score\": 9,\n",
      "        \"reasoning\": \"The provided JSON object represents a well-structured and comprehensive configuration for an AWS Lambda function. It includes all the required properties and additional optional properties that can be useful for configuring the function. The example values are appropriate and reasonable. The only potential weakness is the lack of context or information about how this Lambda function will be used, which could be helpful for a complete review.\"\n",
      "    },\n",
      "    {\n",
      "        \"test_case\": {\n",
      "            \"task\": \"Write a regular expression to validate an AWS S3 bucket name.\",\n",
      "            \"format\": \"regex\",\n",
      "            \"solution_criteria\": \"The regular expression should ensure that the bucket name is between 3 and 63 characters long, starts and ends with a lowercase letter or number, and contains only lowercase letters, numbers, and hyphens.\"\n",
      "        },\n",
      "        \"output\": \"Sure, here's a regular expression that can be used to validate an AWS S3 bucket name:\\n\\n```\\n^[a-z0-9][a-z0-9-]{1,61}[a-z0-9]$\\n```\\n\\nThis regular expression checks for the following criteria:\\n\\n1. The bucket name must start and end with a lowercase letter or a number.\\n2. The bucket name can contain lowercase letters, numbers, and hyphens (-).\\n3. The bucket name must be between 3 and 63 characters long.\\n4. The bucket name cannot contain spaces or uppercase letters.\\n5. The bucket name cannot start or end with a hyphen.\\n\\nHere's a breakdown of the regular expression:\\n\\n- `^`: Matches the beginning of the string.\\n- `[a-z0-9]`: Matches a single lowercase letter or a number.\\n- `[a-z0-9-]{1,61}`: Matches 1 to 61 characters, which can be lowercase letters, numbers, or hyphens.\\n- `[a-z0-9]$`: Matches a single lowercase letter or a number at the end of the string.\\n\\nThis regular expression should work for most valid AWS S3 bucket names, but it's important to note that AWS also has some additional restrictions on bucket names, such as not allowing underscores or certain special characters. You may need to modify the regular expression further if you need to account for those additional requirements.\",\n",
      "        \"score\": 8,\n",
      "        \"reasoning\": \"The provided regular expression covers the key requirements for validating an AWS S3 bucket name, but it does not account for all the additional restrictions that AWS has on bucket names. The solution is a good starting point, but it may need to be expanded to handle edge cases and ensure full compliance with AWS bucket naming rules.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
